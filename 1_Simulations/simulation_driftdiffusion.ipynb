{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Timed drift diffusion models to describe the reaction time in a task with uncertainty\n",
    "By Clara Kuper, December 2020\n",
    "\n",
    "Hypothesis: The time it takes to select a manual movement plan is influenced by the certainty of the sensory evidence and dynamically updated, as the evidence changes.\n",
    "To support this hypothesis, I will fit 3 models to data in a rapid go/no-go paradigm.\n",
    "\n",
    "The first model assumes that the drift rate is fixed for each trial and does not depend on the certainty of sensory evidence.\n",
    "\n",
    "The second model assumes that the drift rate is fixed per trial, depending on the evidence in the first moment a decision threshold is crossed.\n",
    "\n",
    "The third model assumes that the drift rate dynamically changes within the trial, whenever new evidence is presented.\n",
    "\n",
    "All models are topped with a timed process. The rule is simple: If the timed process finishes first, we will make a random decision. If any of the other processes finishes first, we make that decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import math\n",
    "import functools\n",
    "\n",
    "# library for bayesian optimization\n",
    "from skopt import gp_minimize, dump, load\n",
    "import skopt.plots\n",
    "\n",
    "\n",
    "path_figs = '../3_Figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an integrator function that can integrate over functions with a deterministic and a stochastic part\n",
    "# At the same time, this function will also run a \"timer\" that keeps track of when the decision needs to be terminated.\n",
    "\n",
    "def timed_integrator(pfun, ffun, gfun, x0, t, dt, **kwargs):\n",
    "    \"\"\"\n",
    "    integrates functions with a stochastic part.\n",
    "    \n",
    "    input parameters:\n",
    "    pfun: the function that generates parameters for ffun\n",
    "    ffun: function\n",
    "        this is a function that contains the deterministic part of the system of equations\n",
    "    gfun: function\n",
    "        this is a function that contains the stochastic part of the system of equations\n",
    "    x0: the initial starting values of the variable being integrated\n",
    "    t: np.array\n",
    "        the time array in which the function integrates\n",
    "    kwargs: dict\n",
    "        a dicitonary of all arguements beeing passed to pfun and gfun\n",
    "        \n",
    "    \n",
    "    returns: \n",
    "    s: np.array\n",
    "        contains the values of x0 at each timepoint with step size dt.\n",
    "    \"\"\"\n",
    "    # initialize values that will be stacked later in the function\n",
    "    X_t = x0 # first value\n",
    "    s = X_t # array\n",
    "    \n",
    "    # initialize the \"timer\"\n",
    "    #X_tim = 0 # timer starts at zero\n",
    "    #s_tim  = X_tim # here we stack the timer values\n",
    "    \n",
    "    threshold_go = kwargs['threshold_go']\n",
    "    \n",
    "    rt = None\n",
    "    resp = None\n",
    "    \n",
    "    # in case the model integrates over more than one value, we might have different noise levels per condition\n",
    "    if type(X_t) == int:\n",
    "        noiseLen = 1\n",
    "    else:\n",
    "        noiseLen = len(X_t)\n",
    "    \n",
    "    # get the paramters for the functions below\n",
    "    params = pfun(t, **kwargs)\n",
    "    \n",
    "    for time in t[1:]:\n",
    "        Wt = np.random.normal(0,1,noiseLen)\n",
    "        #perform the update step\n",
    "        drift = ffun(time,**params)\n",
    "        X_t1 = X_t + drift*dt + gfun(**kwargs)*np.sqrt(dt)*Wt\n",
    "        #X_tim1 = X_tim + kwargs['tim_drift']*dt + gfun(**kwargs)*np.sqrt(dt)*Wt\n",
    "        \n",
    "        s = np.vstack([s, X_t1])\n",
    "        #s_tim = np.vstack([s_tim, X_tim1])\n",
    "        \n",
    "        # check if threshold was crossed\n",
    "        if abs(X_t1) >= threshold_go and (rt is None):\n",
    "            \n",
    "            rt = time + kwargs['nd_time']\n",
    "            if X_t1>0:\n",
    "                resp = 'go'\n",
    "            else:\n",
    "                resp = 'nogo'\n",
    "            \n",
    "        \n",
    "        X_t = X_t1\n",
    "        #X_tim = X_tim1\n",
    "    \n",
    "    if (rt is None) or (rt > 0.9):\n",
    "            \n",
    "        # if the threshold was never crossed, just compute the remaining duration\n",
    "        rt = 0.9 + (0.5-np.random.sample())*0.1\n",
    "            \n",
    "        if np.random.sample()>=0.5:\n",
    "            resp = 'go'\n",
    "        else:\n",
    "            resp = 'nogo'\n",
    "        \n",
    "    return s, rt, resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise model\n",
    "def stoch_var(**args):\n",
    "    \"\"\"\n",
    "    returns the variance of the noise, as given in the keyword arguments\n",
    "    \"\"\"\n",
    "    \n",
    "    return args['sigma']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I define the models. Important to node, these models take keyword arguments that are generated by another function, specific to the model. Those are defined in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 1\n",
    "\n",
    "def model1(t,**args):\n",
    "    \"\"\"\n",
    "    A drift diffusion model with a fixed drift rate, returns only the drift rate, \n",
    "    the stochastic part is taken care of by the integrator function above \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return args['drift_rate']*args['chosen_resp']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n",
    "def model2(t,**args):\n",
    "    \"\"\"\n",
    "    a model that returns drift rate 0 when evidence at the given time point is below threshold\n",
    "    and return a fixed drift rate when evidence is above the threshold. The drift rate is modulated by \n",
    "    a generic drift rate weight\n",
    "    it takes an argument for the time when the drift starts and the value at which the drift starts\n",
    "    \"\"\"\n",
    "    \n",
    "    evidence = args['evidence_drift']\n",
    "    drift_weight = args['drift_weight']\n",
    "\n",
    "    \n",
    "    if t < args['time_drift']:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return drift_weight * evidence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 3\n",
    "def model3(t,**args):\n",
    "    \n",
    "    \"\"\"\n",
    "    a model that returns the current evidence modulated by \n",
    "    a generic drift rate weight as drift rate\n",
    "    the evidence vector needs the same size and time scale as the time vector\n",
    "    \"\"\"\n",
    "    trial = args['trial']\n",
    "    \n",
    "    try:\n",
    "        last_update = np.argmax(trial['time'][trial['time']<=t])\n",
    "        #print(last_update)\n",
    "        evidence = trial['p_in'].iloc[last_update]\n",
    "        evidence_norm = evidence - 0.5\n",
    "        #print(evidence_norm)\n",
    "        \n",
    "    except:\n",
    "        evidence_norm = 0\n",
    "    \n",
    "    drift_weight = args['drift_weight']\n",
    "    \n",
    "    return drift_weight * evidence_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I define the paramters the models take in. This is specific for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_model1(time, **args):\n",
    "    \n",
    "    \"\"\"\n",
    "    this returns the drift rate value set in the arguments\n",
    "    \"\"\"\n",
    "    try:\n",
    "        first_evidence_val = args['trial']['p_in'][0]\n",
    "    except:\n",
    "        first_evidence_val = args['trial']['p_in']\n",
    "    if first_evidence_val <= 0.5:\n",
    "        chosen_resp = -1\n",
    "    else:\n",
    "        chosen_resp = 1\n",
    "    \n",
    "    params = {\n",
    "        'drift_rate': args['drift_rate'],\n",
    "        'chosen_resp': chosen_resp\n",
    "    }\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate the evidence to a drift rate in model 2\n",
    "def get_params_model2(time, **args):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: evidence - np array with \"time\" and \"p_in\"\n",
    "    \n",
    "    returns \n",
    "    the time point when the threshold is reached (drift start)\n",
    "    and the value for which the threshold is reached (evidence)\n",
    "    \n",
    "    and also returns weight of evidence\n",
    "    \"\"\"\n",
    "    \n",
    "    # normalize p_in\n",
    "    evidence_norm = args['trial']['p_in']-0.5\n",
    "    \n",
    "    # the try-except stucture takes care of cases in which the threshold is never crossed.\n",
    "    try:\n",
    "        # find the first value where the threshold is crossed\n",
    "        idx = np.min(np.where(abs(evidence_norm)>args['threshold_drift'])[0])\n",
    "        # time point of go for drift\n",
    "        time_drift = args['trial']['time'].iloc[idx]\n",
    "        # value of go for drift\n",
    "        evidence_drift = evidence_norm[idx]\n",
    "        \n",
    "        # save paramters\n",
    "        params = {\n",
    "\n",
    "            'time_drift': time_drift,\n",
    "            'evidence_drift': evidence_drift,\n",
    "            'drift_weight': args['drift_weight']\n",
    "        }\n",
    "        \n",
    "    except ValueError:\n",
    "        \n",
    "        # for now the parameters when the threshold is never crossed are set to zero, \n",
    "        # but we could also have a more elaborate decision here\n",
    "        params = {\n",
    "\n",
    "            'time_drift': 0,\n",
    "            'evidence_drift': 0,\n",
    "            'drift_weight': args['drift_weight']\n",
    "        }\n",
    "    \n",
    "    return params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_model3(time, **args):\n",
    "    \n",
    "    \"\"\"\n",
    "    this function returns a vector in the length of the time vector with the corresponding evidence value at each ms.\n",
    "    also, it returns the drift weight\n",
    "    \n",
    "    both values are stored in a dicitonary that is fed into the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'trial': args['trial'],\n",
    "        'drift_weight': args['drift_weight']\n",
    "    }\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_format(data, index):\n",
    "    time = data.loc[index, ['tt_01','tt_02','tt_03','tt_04','tt_05','tt_06','tt_07','tt_08','tt_09','tt_10']]\n",
    "    time_norm = (time - time[0])\n",
    "    \n",
    "    trial = data.loc[index,'trial']\n",
    "    #subject = data.loc[index,'subject']\n",
    "    \n",
    "    p_in = data.loc[index, ['pi_pos01', 'pi_pos02', 'pi_pos03', 'pi_pos04', 'pi_pos05', 'pi_pos06', 'pi_pos07', 'pi_pos08', 'pi_pos09', 'pi_pos10']]\n",
    "    \n",
    "    out_df = pd.concat([time_norm.reset_index(drop = True), p_in.reset_index(drop = True)], axis = 1)\n",
    "    out_df.columns = ['time', 'p_in']\n",
    "    \n",
    "    return(out_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All functions are defined above. Here, we simulate the drift process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from simulated experiment\n",
    "df = pd.read_csv('../0_Simulations/Sim_NoiseStrike1.csv')\n",
    "df['trial'] = np.arange(0,len(df))\n",
    "#df.loc[:,['tt_01','tt_02','tt_03','tt_04','tt_05','tt_06','tt_07','tt_08','tt_09','tt_10']] = 1000*df.loc[:,['tt_01','tt_02','tt_03','tt_04','tt_05','tt_06','tt_07','tt_08','tt_09','tt_10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "729\n",
      "0\n",
      "729\n",
      "729\n",
      "1\n",
      "729\n",
      "729\n",
      "2\n",
      "729\n",
      "729\n",
      "3\n",
      "729\n",
      "729\n",
      "4\n",
      "729\n",
      "729\n",
      "5\n",
      "729\n",
      "729\n",
      "6\n",
      "729\n",
      "729\n",
      "7\n",
      "729\n",
      "729\n",
      "8\n",
      "729\n",
      "729\n",
      "9\n",
      "729\n",
      "729\n",
      "10\n",
      "729\n",
      "729\n",
      "11\n",
      "729\n",
      "729\n",
      "12\n",
      "729\n",
      "729\n",
      "13\n",
      "729\n",
      "729\n",
      "14\n",
      "729\n",
      "729\n",
      "15\n",
      "729\n",
      "729\n",
      "16\n",
      "729\n",
      "729\n",
      "17\n",
      "729\n",
      "729\n",
      "18\n",
      "729\n",
      "729\n",
      "19\n",
      "729\n",
      "729\n",
      "20\n",
      "729\n",
      "729\n",
      "21\n",
      "729\n",
      "729\n",
      "22\n",
      "729\n",
      "729\n",
      "23\n",
      "729\n",
      "729\n",
      "24\n",
      "729\n",
      "729\n",
      "25\n",
      "729\n",
      "729\n",
      "26\n",
      "729\n",
      "729\n",
      "27\n",
      "729\n",
      "729\n",
      "28\n",
      "729\n",
      "729\n",
      "29\n",
      "729\n",
      "729\n",
      "30\n",
      "729\n",
      "729\n",
      "31\n",
      "729\n",
      "729\n",
      "32\n",
      "729\n",
      "729\n",
      "33\n",
      "729\n",
      "729\n",
      "34\n",
      "729\n",
      "729\n",
      "35\n",
      "729\n",
      "729\n",
      "36\n",
      "729\n",
      "729\n",
      "37\n",
      "729\n",
      "729\n",
      "38\n",
      "729\n",
      "729\n",
      "39\n",
      "729\n",
      "729\n",
      "40\n",
      "729\n",
      "729\n",
      "41\n",
      "729\n",
      "729\n",
      "42\n",
      "729\n",
      "729\n",
      "43\n",
      "729\n",
      "729\n",
      "44\n",
      "729\n",
      "729\n",
      "45\n",
      "729\n",
      "729\n",
      "46\n",
      "729\n",
      "729\n",
      "47\n",
      "729\n",
      "729\n",
      "48\n",
      "729\n",
      "729\n",
      "49\n",
      "729\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulate Drift\n",
    "\n",
    "# define fixed params\n",
    "X0 = 0 # start value of the drift process\n",
    "dt = 0.01 # integration time step\n",
    "dur = 1 # time for which we run the simulation\n",
    "T = np.arange(0, dur, dt) # time vector for the simulation\n",
    "\n",
    "# define variable params:\n",
    "sigma = 0.0 # variance\n",
    "drift_weight = 10.0\n",
    "threshold_drift = 0.15\n",
    "drift_rate = 3.0\n",
    "threshold_go = 1\n",
    "nd_time = 0.2\n",
    "\n",
    "# initialize plot\n",
    "fig, ax = plt.subplots(1,3, figsize = (12,3), sharex = True, sharey = True)\n",
    "trial_n = len(np.unique(df['trial']))\n",
    "\n",
    "for n in np.arange(50):\n",
    "\n",
    "    # set up data frames\n",
    "    m1_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "    m2_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "    m3_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "\n",
    "    m1_rt = pd.Series(np.zeros(trial_n))\n",
    "    m2_rt = pd.Series(np.zeros(trial_n))\n",
    "    m3_rt = pd.Series(np.zeros(trial_n))\n",
    "\n",
    "    m1_resp = pd.Series(np.zeros(trial_n))\n",
    "    m2_resp = pd.Series(np.zeros(trial_n))\n",
    "    m3_resp = pd.Series(np.zeros(trial_n))\n",
    "\n",
    "    ## Start simulation\n",
    "\n",
    "    color = iter(plt.cm.Greys_r(np.linspace(0,1,25)))\n",
    "    print(len(df))\n",
    "    for idx, trial in enumerate(np.unique(df['trial'])):\n",
    "        # get data from current trial only\n",
    "        trial_data = long_format(df, trial)\n",
    "        trial_data.reset_index(drop=True, inplace = True)\n",
    "\n",
    "        # set parameters for drift\n",
    "        trial_params = {\n",
    "        'sigma': sigma,\n",
    "        'trial': trial_data,\n",
    "        'drift_weight': drift_weight,\n",
    "        'threshold_drift': threshold_drift,\n",
    "        'drift_rate': drift_rate,   \n",
    "        'threshold_go': threshold_go,\n",
    "        'nd_time': nd_time\n",
    "        }\n",
    "\n",
    "        # run drift diffusion    \n",
    "        simulation_m1, rt_m1,res_m1 = timed_integrator(get_params_model1, model1, stoch_var, X0, T, dt, **trial_params)\n",
    "        simulation_m2, rt_m2,res_m2 = timed_integrator(get_params_model2, model2, stoch_var, X0, T, dt, **trial_params)\n",
    "        simulation_m3, rt_m3,res_m3 = timed_integrator(get_params_model3, model3, stoch_var, X0, T, dt, **trial_params)\n",
    "\n",
    "        # write drift result to table\n",
    "        m1_drift.iloc[idx,:] = simulation_m1.T[0]\n",
    "        m1_rt.iloc[idx] = rt_m1\n",
    "        m1_resp.iloc[idx] = res_m1\n",
    "\n",
    "        m2_drift.iloc[idx,:] = simulation_m2.T[0]\n",
    "        m2_rt.iloc[idx] = rt_m2\n",
    "        m2_resp.iloc[idx] = res_m2\n",
    "\n",
    "        m3_drift.iloc[idx,:] = simulation_m3.T[0]\n",
    "        m3_rt.iloc[idx] = rt_m3\n",
    "        m3_resp.iloc[idx] = res_m3\n",
    "\n",
    "\n",
    "        # plot if needed    \n",
    "        if trial % 111 == 0:\n",
    "            c = next(color)\n",
    "            ax[0].plot(T, simulation_m1, color = c)\n",
    "            ax[0].set_title('model 1')\n",
    "            ax[0].set_xlabel('time')\n",
    "            ax[0].set_ylabel('drift value')\n",
    "            ax[1].plot(T, simulation_m2, color = c)\n",
    "            ax[1].set_title('model 2')\n",
    "            ax[1].set_xlabel('time')\n",
    "            ax[2].plot(T, simulation_m3, color = c)\n",
    "            ax[2].set_title('model 3')\n",
    "            ax[2].set_xlabel('time')\n",
    "        \n",
    "    try:\n",
    "        print(n)\n",
    "        print(len(m1_drift))\n",
    "        NS2_drift_m1 = pd.concat([NS2_drift_m1, m1_drift], axis = 0)\n",
    "        NS2_rt_m1 = pd.concat([NS2_rt_m1, m1_rt], axis = 0)\n",
    "        NS2_resp_m1 = pd.concat([NS2_resp_m1, m1_resp], axis = 0)\n",
    "        \n",
    "        NS2_drift_m2 = pd.concat([NS2_drift_m2, m2_drift], axis = 0)\n",
    "        NS2_rt_m2 = pd.concat([NS2_rt_m2, m2_rt], axis = 0)\n",
    "        NS2_resp_m2 = pd.concat([NS2_resp_m2, m2_resp], axis = 0)\n",
    "        \n",
    "        NS2_drift_m3 = pd.concat([NS2_drift_m3, m3_drift], axis = 0)\n",
    "        NS2_rt_m3 = pd.concat([NS2_rt_m3, m3_rt], axis = 0)\n",
    "        NS2_resp_m3 = pd.concat([NS2_resp_m3, m3_resp], axis = 0)\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        NS2_drift_m1 = m1_drift\n",
    "        NS2_rt_m1 = m1_rt\n",
    "        NS2_resp_m1 = m1_resp\n",
    "        \n",
    "        NS2_drift_m2 = m2_drift\n",
    "        NS2_rt_m2 = m2_rt\n",
    "        NS2_resp_m2 = m2_resp\n",
    "        \n",
    "        NS2_drift_m3 = m3_drift\n",
    "        NS2_rt_m3 = m3_rt\n",
    "        NS2_resp_m3 = m3_resp\n",
    "        \n",
    "#plt.savefig(path_figs + 'timed_ddm_models_NoiseStrike2.png')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fig, model_ax = plt.subplots(1,3, figsize = [13, 3], sharex = True, sharey = True)\n",
    "color = iter(plt.cm.Greys(np.linspace(0,1,8))[2:])\n",
    "\n",
    "for t,c in zip([3, 136,533, 710, 110, 113],color):\n",
    "    \n",
    "    model_ax[0].plot(T, m1_drift.loc[t,:], color = c)\n",
    "    model_ax[0].set_title('model 1')\n",
    "    model_ax[0].set_xlabel('time')\n",
    "    model_ax[0].set_ylabel('drift value')\n",
    "    model_ax[1].plot(T, m2_drift.loc[t,:], color = c)\n",
    "    model_ax[1].set_title('model 2')\n",
    "    model_ax[1].set_xlabel('time')\n",
    "    model_ax[1].set_ylabel('drift value')\n",
    "    model_ax[2].plot(T, m3_drift.loc[t,:], color = c)\n",
    "    model_ax[2].set_title('model 2')\n",
    "    model_ax[2].set_xlabel('time')\n",
    "    model_ax[2].set_ylabel('drift value')\n",
    "    \n",
    "plt.savefig(path_figs + 'timed_ddm_models_NoiseStrike2.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(m3_drift.loc[113,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_rsp_m1 = pd.concat([df,m1_resp], axis = 1)\n",
    "dat_rsp_m2 = pd.concat([df,m2_resp], axis = 1)\n",
    "dat_rsp_m3 = pd.concat([df,m3_resp], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_rsp_m1.to_csv('dat_rsp_m1_noise0.csv')\n",
    "dat_rsp_m2.to_csv('dat_rsp_m2_noise0.csv')\n",
    "dat_rsp_m3.to_csv('dat_rsp_m3_noise0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NS2_drift_m1.reset_index(drop=True, inplace = True)\n",
    "NS2_rt_m1.reset_index(drop=True, inplace = True)\n",
    "NS2_resp_m1.reset_index(drop=True, inplace = True)\n",
    "        \n",
    "NS2_drift_m2.reset_index(drop=True, inplace = True)\n",
    "NS2_rt_m2.reset_index(drop=True, inplace = True)\n",
    "NS2_resp_m2.reset_index(drop=True, inplace = True)\n",
    "        \n",
    "NS2_drift_m3.reset_index(drop=True, inplace = True)\n",
    "NS2_rt_m3.reset_index(drop=True, inplace = True)\n",
    "NS2_resp_m3.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi, ax = plt.subplots(1)\n",
    "for d in [378, 387, 388, 396, 397, 398]:\n",
    "    ax.plot(NS2_drift_m3.loc[d,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_drift.to_csv('m1_drift.csv', sep=',')\n",
    "m2_drift.to_csv('m2_drift.csv', sep=',')\n",
    "m3_drift.to_csv('m3_drift.csv', sep=',')\n",
    "\n",
    "m1_rt.to_csv('m1_rt.csv', sep =',') \n",
    "m2_rt.to_csv('m2_rt.csv', sep =',') \n",
    "m3_rt.to_csv('m3_rt.csv', sep =',') \n",
    "\n",
    "m1_resp.to_csv('m1_resp.csv', sep =',') \n",
    "m2_resp.to_csv('m2_resp.csv', sep =',') \n",
    "m3_resp.to_csv('m3_resp.csv', sep =',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of simulating new data, we load the data we've simulated last time\n",
    "m1_drift = pd.read_csv('m1_drift.csv')\n",
    "m2_drift = pd.read_csv('m2_drift.csv')\n",
    "m3_drift = pd.read_csv('m3_drift.csv')\n",
    "\n",
    "m1_rt = pd.read_csv('m1_rt.csv')\n",
    "m2_rt = pd.read_csv('m2_rt.csv')\n",
    "m3_rt = pd.read_csv('m3_rt.csv')\n",
    "\n",
    "m1_resp = pd.read_csv('m1_resp.csv')\n",
    "m2_resp = pd.read_csv('m2_resp.csv')\n",
    "m3_resp = pd.read_csv('m3_resp.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot, hist_axs = plt.subplots(1,3, figsize = (15,3), sharex=False, sharey=False)\n",
    "\n",
    "hist_axs[0].hist(m1_rt);\n",
    "hist_axs[1].hist(m2_rt[m2_rt<1]);\n",
    "hist_axs[2].hist(m3_rt[m3_rt<1]);\n",
    "\n",
    "print(mse(m2_rt[m3_rt<1],m3_rt[m3_rt<1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean drift of each model in each tp\n",
    "m1_mean = np.mean(abs(m1_drift),axis = 0)\n",
    "m2_mean = np.mean(abs(m2_drift),axis = 0)\n",
    "m3_mean = np.mean(abs(m3_drift),axis = 0)\n",
    "\n",
    "fig2,ax2 = plt.subplots(1,1);\n",
    "\n",
    "ax2.plot(T,m1_mean, label = 'm1')\n",
    "ax2.plot(T,m2_mean, label = 'm2')\n",
    "ax2.plot(T,m3_mean, label = 'm3')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('time in s')\n",
    "ax2.set_ylabel('means absolute drift value');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reminder, these are the values we set to generate the decisions above:\n",
    "    \n",
    "\n",
    "    sigma = 1 \n",
    "    drift_weight = 4.0\n",
    "    threshold_drift = 0.3\n",
    "    drift_rate = 1.5\n",
    "    threshold_go = 0.5\n",
    "        \n",
    "Let's try if we can fit these paramters :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared errors function\n",
    "def mse(modelled_data, measured_data):\n",
    "    \"\"\"\n",
    "    returns the mean squared error between two data sets. Important: both datasets need to have the same length\n",
    "    \"\"\"\n",
    "    mse = np.mean((modelled_data-measured_data)**2)\n",
    "    return mse\n",
    "\n",
    "# build an objective function\n",
    "\n",
    "def objective_m1(params, X0 = 0, dt = dt, threshold_go = threshold_go, df = df):\n",
    "    \n",
    "    \"\"\"\n",
    "    The objective we are trying to minimize later - takes the paramters we are using to fit the function\n",
    "    fits the function as refined and\n",
    "    returns a metric to evaluate the function fit to the data (mse in this case)\n",
    "    this objective function is fed into the optimizer function.\n",
    "    \n",
    "    Some variables need to be defined before executing this function:\n",
    "    data_go = the experimental setup and information for every trial (with or without no_gos).\n",
    "    drift_slice = the indices to trials with \"go\" responses (= trial numbers)\n",
    "    m1_drift_go = the measured data - same length as data_slice\n",
    "    \"\"\"\n",
    "    \n",
    "    # unpack params\n",
    "    drift_rate = params[0]\n",
    "    tim_drift = params[1]\n",
    "        \n",
    "    # constant params\n",
    "    data = df.reset_index(drop = True)\n",
    "    sigma = 1\n",
    "    \n",
    "    range_max = np.round(m1_rt.max(),1)\n",
    "    bin_width = 0.1\n",
    "    num_bins = int(np.round(range_max/bin_width))\n",
    "    \n",
    "    go_m1_rt = m1_rt[m1_resp == 'go']\n",
    "    bins_obs = np.histogram(go_m1_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "    bins_obs = np.hstack([bins_obs, len(m1_resp[m1_resp == 'nogo'])])\n",
    "    \n",
    "    dur = max(data['time']) # time for which we run the simulation\n",
    "    T = np.arange(0, dur, dt) # time vector for the simulation\n",
    "    \n",
    "    # init data frames\n",
    "    sim_drift = pd.DataFrame(np.zeros((len(np.unique(data['trial'])),len(T))))\n",
    "    sim_rt = pd.Series(np.zeros(len(np.unique(data['trial']))))\n",
    "    sim_resp = pd.Series(np.zeros(len(np.unique(data['trial']))))    \n",
    "            \n",
    "    # get reaction for every trial\n",
    "    for idx, trial in enumerate(np.unique(data['trial'])): \n",
    "        # find the experimental setup for the given trial\n",
    "        trial_data = data[data['trial'] == trial] \n",
    "        trial_data.reset_index(drop=True, inplace = True)\n",
    "        \n",
    "        # parameters for drift\n",
    "        trial_params = {\n",
    "        'sigma': sigma,\n",
    "        'drift_rate': drift_rate,\n",
    "        'tim_drift': tim_drift,\n",
    "        'trial': trial_data,\n",
    "        'threshold_go': threshold_go,\n",
    "        'nd_time' : 0\n",
    "        }\n",
    "        \n",
    "        model1_drift, tim , rt, resp = timed_integrator(get_params_model1, model1, stoch_var, X0, T, dt, **trial_params)\n",
    "\n",
    "        # write out information in data frame\n",
    "        sim_drift.iloc[idx,0:len(model1_drift)] = model1_drift.T[0]\n",
    "        sim_rt.iloc[idx] = rt\n",
    "        sim_resp.iloc[idx] = resp\n",
    "                                             \n",
    "    try:\n",
    "        #compute mse\n",
    "        # output = mse(sim_rt, x)\n",
    "        \n",
    "        # compute chi squared\n",
    "        go_sim_rt = sim_rt[sim_resp=='go']\n",
    "        bins_est = np.histogram(go_sim_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "        bins_est = np.hstack([bins_est, len(sim_resp[sim_resp == 'nogo'])])\n",
    "        \n",
    "        if np.any(bins_est == 0):\n",
    "            print('zero division detected, needed to correct')\n",
    "            bins_est[bins_est == 0] = 1\n",
    "        \n",
    "        output, p = scipy.stats.chisquare(bins_obs, bins_est)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # if something goes wrong, let us know a few things:\n",
    "        print(sim_rt)\n",
    "        print(x)\n",
    "        print('the drift rate was: {}'.format(drift_rate))\n",
    "        print('sigma was: {}'.format(sigma))\n",
    "        \n",
    "        raise e\n",
    "    if np.isnan(output) or (not np.isfinite(output)):\n",
    "        print('nan detected')\n",
    "    print('objective evaluated at drift_rate: {}, time_drift: {}'.format(drift_rate, tim_drift))\n",
    "    print('the discovered p_value was: {}'.format(p))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter space where we want to look\n",
    "space = [(0.0,2.0),#drift rate\n",
    "        (0.5, 1.5)] # tim_drift\n",
    "\n",
    "# run the optimizer\n",
    "try:\n",
    "    r = gp_minimize(objective_m1,space,n_calls=20,random_state=1);   \n",
    "except ValueError as e:\n",
    "    print(r)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.x)\n",
    "print(r.fun)\n",
    "skopt.plots.plot_objective(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an objective function\n",
    "\n",
    "def objective_m2(params, X0 = 0, dt = dt, threshold_go = threshold_go, df = df):\n",
    "    \n",
    "    \"\"\"\n",
    "    The objective we are trying to minimize later - takes the paramters we are using to fit the function\n",
    "    fits the function as refined and\n",
    "    returns a metric to evaluate the function fit to the data (mse in this case)\n",
    "    this objective function is fed into the optimizer function.\n",
    "    \n",
    "    Some variables need to be defined before executing this function:\n",
    "    data_go = the experimental setup and information for every trial (with or without no_gos).\n",
    "    drift_slice = the indices to trials with \"go\" responses (= trial numbers)\n",
    "    m2_drift_go = the measured data - same length as data_slice\n",
    "    \"\"\"\n",
    "    \n",
    "    # unpack params\n",
    "    drift_weight = params[0]\n",
    "    threshold_drift = params[1]\n",
    "    time_drift = params[2]\n",
    "    \n",
    "    \n",
    "    # constant params\n",
    "    data = df.reset_index(drop=True) # data_go needs to be defined in the workspace before executing this function\n",
    "    #x = m2_rt.reset_index(drop=True) #m1_drift_go needs to be defined before executing\n",
    "    sigma = 1\n",
    "    \n",
    "    range_max = np.round(m2_rt.max(),1)\n",
    "    bin_width = 0.1\n",
    "    num_bins = int(np.round(range_max/bin_width))\n",
    "    \n",
    "    go_m2_rt = m2_rt[m2_resp == 'go']\n",
    "    bins_obs = np.histogram(go_m2_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "    bins_obs = np.hstack([bins_obs, len(m2_resp[m2_resp == 'nogo'])])\n",
    "    \n",
    "    dur = max(data['time']) # time for which we run the simulation\n",
    "    T = np.arange(0, dur, dt) # time vector for the simulation\n",
    "    \n",
    "    # init data frames\n",
    "    sim_drift = pd.DataFrame(np.zeros((len(np.unique(data['trial'])),len(T))))\n",
    "    sim_rt  = pd.Series(np.zeros(len(np.unique(data['trial']))))\n",
    "    sim_resp = pd.Series(np.zeros(len(np.unique(data['trial']))))\n",
    "     \n",
    "    # get reaction for every trial\n",
    "    for idx, trial in enumerate(np.unique(data['trial'])): \n",
    "        # find the experimental setup for the given trial\n",
    "        trial_data = data[data['trial'] == trial] \n",
    "        trial_data.reset_index(drop=True, inplace = True)\n",
    "\n",
    "        # parameters for drift\n",
    "        trial_params = {\n",
    "        'sigma': sigma,\n",
    "        'drift_weight': drift_weight,\n",
    "        'threshold_drift': threshold_drift,\n",
    "        'trial': trial_data,\n",
    "        'tim_drift': time_drift,\n",
    "        'threshold_go': threshold_go,\n",
    "        'nd_time': 0\n",
    "        }\n",
    "        \n",
    "        model2_drift, tim, rt, resp = timed_integrator(get_params_model2, model2, stoch_var, X0, T, dt, **trial_params)\n",
    "        #if resp != \"go\":\n",
    "        #    # penalize wrong no_go decisions of cases when the decision boundary was not reached\n",
    "        #    rt = 9999\n",
    "        # write out information in data frame\n",
    "        sim_drift.iloc[idx,:] = model2_drift.T[0]\n",
    "        sim_rt.iloc[idx] = rt\n",
    "        sim_resp.iloc[idx] = resp\n",
    "                                             \n",
    "    try:\n",
    "        #compute mse\n",
    "        #output = mse(sim_rt, x)\n",
    "        #compute chi squared\n",
    "        \n",
    "        go_sim_rt = sim_rt[sim_resp=='go']\n",
    "        bins_est = np.histogram(go_sim_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "        bins_est = np.hstack([bins_est, len(sim_resp[sim_resp == 'nogo'])])\n",
    "        \n",
    "        if np.any(bins_est == 0):\n",
    "            print('zero division detected, needed to correct')\n",
    "            bins_est[bins_est == 0] = 1\n",
    "        \n",
    "        output, p = scipy.stats.chisquare(bins_obs, bins_est)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # if something goes wrong, let us know a few things:\n",
    "        print(sim_rt)\n",
    "        print(x)\n",
    "        print('the drift rate was: {}'.format(drift_rate))\n",
    "        print('sigma was: {}'.format(sigma))\n",
    "        \n",
    "        raise e\n",
    "        \n",
    "    print('objective evaluated at drift_weight: {},threshold_drift: {}, time_drift: {}'.format(drift_weight, threshold_drift, time_drift))\n",
    "    print('the discovered p_value was: {}'.format(p))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter space where we want to look\n",
    "space2 = [(1.0,5.0),#drift weight\n",
    "          (0, 0.5), #threshold drift\n",
    "          (0.0, 2.0)] # time drift\n",
    "\n",
    "# run the optimizer\n",
    "r2 = gp_minimize(objective_m2,space2,n_calls=20,random_state=1); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2.x)\n",
    "skopt.plots.plot_objective(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an objective function\n",
    "\n",
    "def objective_m3(params,X0 = 0, dt = dt, threshold_go = threshold_go, df = df):\n",
    "    \n",
    "    \"\"\"\n",
    "    The objective we are trying to minimize later - takes the paramters we are using to fit the function\n",
    "    fits the function as refined and\n",
    "    returns a metric to evaluate the function fit to the data (mse in this case)\n",
    "    this objective function is fed into the optimizer function.\n",
    "    \n",
    "    Some variables need to be defined before executing this function:\n",
    "    data_go = the experimental setup and information for every trial (with or without no_gos).\n",
    "    drift_slice = the indices to trials with \"go\" responses (= trial numbers)\n",
    "    m3_drift_go = the measured data - same length as data_slice\n",
    "    \"\"\"\n",
    "    \n",
    "    # unpack params\n",
    "    drift_weight = params[0]\n",
    "    time_drift = params [1]\n",
    "    \n",
    "    # constant params\n",
    "    data = df.reset_index(drop=True) # data_go needs to be defined in the workspace before executing this function\n",
    "    sigma = 1\n",
    "    \n",
    "    range_max = np.round(m3_rt.max(),1)\n",
    "    bin_width = 0.1\n",
    "    num_bins = int(np.round(range_max/bin_width))\n",
    "    \n",
    "    go_m3_rt = m3_rt[m3_resp == 'go']\n",
    "    bins_obs = np.histogram(go_m3_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "    bins_obs = np.hstack([bins_obs, len(m3_resp[m3_resp == 'nogo'])])\n",
    "    \n",
    "    #x = m3_drift_go.reset_index(drop=True) #m1_drift_go needs to be defined before executing\n",
    "\n",
    "    dur = max(data['time']) # time for which we run the simulation\n",
    "    T = np.arange(0, dur, dt) # time vector for the simulation\n",
    "    \n",
    "    # init data frames\n",
    "    sim_drift = pd.DataFrame(np.zeros((len(np.unique(data['trial'])),len(T))))\n",
    "    sim_rt  = pd.Series(np.zeros(len(np.unique(data['trial']))))\n",
    "    sim_resp = pd.Series(np.zeros(len(np.unique(data['trial']))))\n",
    "     \n",
    "    # get reaction for every trial\n",
    "    for idx, trial in enumerate(np.unique(data['trial'])): \n",
    "        # find the experimental setup for the given trial\n",
    "        trial_data = data[data['trial'] == trial] \n",
    "        trial_data.reset_index(drop=True, inplace = True)\n",
    "\n",
    "        # parameters for drift\n",
    "        trial_params = {\n",
    "        'sigma': sigma,\n",
    "        'drift_weight': drift_weight,\n",
    "        'tim_drift': time_drift,\n",
    "        'trial': trial_data,\n",
    "        'threshold_go': threshold_go,\n",
    "        'nd_time': 0\n",
    "        }\n",
    "        \n",
    "        model3_drift, tim, rt, resp = timed_integrator(get_params_model3, model3, stoch_var, X0, T, dt, **trial_params)\n",
    "        #if resp != \"go\":\n",
    "            # penalize wrong no_go decisions of cases when the decision boundary was not reached\n",
    "        #    rt = 9999\n",
    "        # write out information in data frame\n",
    "        sim_drift.iloc[idx,0:len(model3_drift)] = model3_drift.T[0]\n",
    "        sim_rt[idx] = rt\n",
    "        sim_resp[idx] = resp\n",
    "                                             \n",
    "    try:\n",
    "        # compute mse\n",
    "        # output = mse(sim_rt, x)\n",
    "        # compute chi squared\n",
    "        go_sim_rt = sim_rt[sim_resp=='go']\n",
    "        bins_est = np.histogram(go_sim_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "        bins_est = np.hstack([bins_est, len(sim_resp[sim_resp == 'nogo'])])\n",
    "        \n",
    "        if np.any(bins_est == 0):\n",
    "            print('zero division detected, needed to correct')\n",
    "            bins_est[bins_est == 0] = 1\n",
    "        \n",
    "        output, p = scipy.stats.chisquare(bins_obs, bins_est)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # if something goes wrong, let us know a few things:\n",
    "        print(sim_rt)\n",
    "        print(x)\n",
    "        print('the drift rate was: {}'.format(drift_rate))\n",
    "        print('sigma was: {}'.format(sigma))\n",
    "        \n",
    "        raise e\n",
    "    \n",
    "    print('objective evaluated at drift_weight: {}, time_drift: {}'.format(drift_weight, time_drift))\n",
    "    print('the discovered p_value was: {}'.format(p))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter space where we want to look\n",
    "space3 = [(1.0,5.0),#drift weight\n",
    "         (0.0,2.0)]# time drift\n",
    "\n",
    "# run the optimizer\n",
    "r3 = gp_minimize(objective_m3,space3,n_calls=20,random_state=1); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r3.x)\n",
    "skopt.plots.plot_objective(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the models to the simulation visually\n",
    "\n",
    "model_comp, mc_axs = plt.subplots(1,3, figsize = [15,5])\n",
    "\n",
    "est_m1_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "est_m2_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "est_m3_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "\n",
    "est_m1_rt = pd.Series(np.zeros(trial_n))\n",
    "est_m2_rt = pd.Series(np.zeros(trial_n))\n",
    "est_m3_rt = pd.Series(np.zeros(trial_n))\n",
    "\n",
    "est_m1_resp = pd.Series(np.zeros(trial_n))\n",
    "est_m2_resp = pd.Series(np.zeros(trial_n))\n",
    "est_m3_resp = pd.Series(np.zeros(trial_n))\n",
    "\n",
    "for idx, trial in enumerate(np.unique(df['trial'])):\n",
    "    \n",
    "    # get data from current trial only\n",
    "    trial_data = df[df['trial'] == trial] \n",
    "    trial_data.reset_index(drop=True, inplace = True)\n",
    "    #print(trial_data.loc[0])\n",
    "    # set parameters for drift\n",
    "    \n",
    "    trial_params1 = {\n",
    "        'sigma': 1,\n",
    "        'trial': trial_data,\n",
    "        'drift_weight': 4,\n",
    "        'threshold_drift': 0.3,\n",
    "        'drift_rate': r.x[0],\n",
    "        'tim_drift': r.x[1],    \n",
    "        'threshold_go': 0.5,\n",
    "        'nd_time': 0 \n",
    "        }\n",
    "    \n",
    "    trial_params2= {\n",
    "        'sigma': 1,\n",
    "        'trial': trial_data,\n",
    "        'drift_weight': r2.x[0],\n",
    "        'threshold_drift': r2.x[1],\n",
    "        'drift_rate': 1.5,\n",
    "        'tim_drift': r2.x[2],    \n",
    "        'threshold_go': 0.5,\n",
    "        'nd_time': 0 \n",
    "        }\n",
    "    \n",
    "    trial_params3= {\n",
    "        'sigma': 1,\n",
    "        'trial': trial_data,\n",
    "        'drift_weight': r3.x[0],\n",
    "        'threshold_drift': 0.3,\n",
    "        'drift_rate': 1.5,\n",
    "        'tim_drift': r2.x[1],    \n",
    "        'threshold_go': 0.5,\n",
    "        'nd_time': 0 \n",
    "        }\n",
    "    \n",
    "    # run drift diffusion    \n",
    "    est_m1, est_time_m1, est_rt_m1,est_res_m1 = timed_integrator(get_params_model1, model1, stoch_var, X0, T, dt, **trial_params1)\n",
    "    est_m2, est_time_m2, est_rt_m2,est_res_m2 = timed_integrator(get_params_model2, model2, stoch_var, X0, T, dt, **trial_params2)\n",
    "    est_m3, est_time_m3, est_rt_m3,est_res_m3 = timed_integrator(get_params_model3, model3, stoch_var, X0, T, dt, **trial_params3)\n",
    "    \n",
    "    # write drift result to table\n",
    "    est_m1_drift.iloc[idx,:] = est_m1.T[0]\n",
    "    est_m1_rt.iloc[idx] = est_rt_m1\n",
    "    est_m1_resp.iloc[idx] = est_res_m1\n",
    "\n",
    "    est_m2_drift.iloc[idx,:] = est_m2.T[0]\n",
    "    est_m2_rt.iloc[idx] = est_rt_m2\n",
    "    est_m2_resp.iloc[idx] = est_res_m2\n",
    "\n",
    "    est_m3_drift.iloc[idx,:] = est_m3.T[0]\n",
    "    est_m3_rt.iloc[idx] = est_rt_m3\n",
    "    est_m3_resp.iloc[idx] = est_res_m3\n",
    "    \n",
    "t = 0.1 \n",
    "bins_sim = math.ceil((0.7 - 0.0)/t)\n",
    "bins_est = math.ceil((0.7-0.0)/t)\n",
    "\n",
    "mc_axs[0].hist(est_m1_rt[est_m1_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est)\n",
    "mc_axs[0].hist(m1_rt[m1_resp == 'go'], alpha = 0.5, label = 'simulated', bins = bins_sim)\n",
    "\n",
    "mc_axs[1].hist(est_m2_rt[est_m2_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est)\n",
    "mc_axs[1].hist(m2_rt[m2_resp == 'go'], alpha = 0.5, label = 'simulated', bins = bins_sim)\n",
    "\n",
    "mc_axs[2].hist(est_m3_rt[est_m3_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est, range= [0,0.7])\n",
    "mc_axs[2].hist(m3_rt[m3_resp == 'go'], alpha = 0.5, label = 'simulated', bins = bins_sim, range= [0,0.7]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the 3 models to the observed response times\n",
    "\n",
    "# step1 : reshape the full data set to make it usable for the model\n",
    "exp_des = pd.read_csv('../2_cleaned/df_cleaned_rc_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def long_format(data, index):\n",
    "    time = data.loc[index, ['tt_1','tt_2','tt_3','tt_4','tt_5','tt_6']]\n",
    "    time_norm = (time - time[0])/1000\n",
    "    \n",
    "    trial = data.loc[index,'trial']\n",
    "    subject = data.loc[index,'subject']\n",
    "    \n",
    "    p_in = data.loc[index, ['pi_pos01', 'pi_pos02', 'pi_pos03', 'pi_pos04', 'pi_pos05', 'pi_pos06']]\n",
    "    \n",
    "    out_df = pd.concat([time_norm.reset_index(drop = True), p_in.reset_index(drop = True)], axis = 1)\n",
    "    out_df.columns = ['time', 'p_in']\n",
    "    \n",
    "    return(out_df)\n",
    "    \n",
    "long_format(exp_des,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by fitting one subject:\n",
    "\n",
    "sub_dat = exp_des[exp_des.subject == 'AE'].reset_index(drop = True)\n",
    "true_rt = sub_dat.rea_time\n",
    "true_resp = sub_dat.goResp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_objective(params, X0 = 0, dt = 0.001, threshold_go = 1, df = None, m_func = None, par_func = None, model = None, rts = None, resps = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    The objective we are trying to minimize later - takes the paramters we are using to fit the function\n",
    "    fits the function as refined and\n",
    "    returns a metric to evaluate the function fit to the data (mse in this case)\n",
    "    this objective function is fed into the optimizer function.\n",
    "    \n",
    "    Some variables need to be defined before executing this function:\n",
    "    data_go = the experimental setup and information for every trial (with or without no_gos).\n",
    "    drift_slice = the indices to trials with \"go\" responses (= trial numbers)\n",
    "    m1_drift_go = the measured data - same length as data_slice\n",
    "    \"\"\"\n",
    "    if model == 1:\n",
    "        # unpack params\n",
    "        drift_rate = params[0]\n",
    "        tim_drift = params[1]\n",
    "        nd_time = params[2]\n",
    "    \n",
    "    elif model == 2: \n",
    "        # unpack params\n",
    "        drift_weight = params[0]\n",
    "        threshold_drift = params[1]\n",
    "        time_drift = params[2]\n",
    "        nd_time = params[3]\n",
    "        \n",
    "    elif model == 3:\n",
    "        # unpack params\n",
    "        drift_weight = params[0]\n",
    "        time_drift = params [1]\n",
    "        nd_time = params[2]\n",
    "        \n",
    "    # constant params\n",
    "    data = df.reset_index(drop = True)\n",
    "    sigma = 0\n",
    "    \n",
    "    range_max = np.round(rts.max(),1)\n",
    "    bin_width = 0.1\n",
    "    num_bins = int(np.round(range_max/bin_width))\n",
    "    \n",
    "    go_rt = rts[resps == 1]\n",
    "    bins_obs = np.histogram(go_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "    bins_obs = np.hstack([bins_obs, len(resps[resps == 0])])\n",
    "    \n",
    "    dur = 1 # time for which we run the simulation\n",
    "    T = np.arange(0, dur, dt) # time vector for the simulation\n",
    "    \n",
    "    # init data frames\n",
    "    sim_drift = pd.DataFrame(np.zeros((len(data),len(T))))\n",
    "    sim_time = pd.DataFrame(np.zeros((len(data),len(T))))\n",
    "    sim_rt = pd.Series(np.zeros(len(data)))\n",
    "    sim_resp = pd.Series(np.zeros(len(data)))    \n",
    "            \n",
    "    # get reaction for every trial\n",
    "    for idx, trial in enumerate(data.index): \n",
    "        \n",
    "        # find the experimental setup for the given trial\n",
    "        trial_data = long_format(data, trial) \n",
    "        trial_data.reset_index(drop=True, inplace = True)\n",
    "        \n",
    "        # parameters for drift\n",
    "        if model  == 1:\n",
    "            trial_params = {\n",
    "            'sigma': sigma,\n",
    "            'drift_rate': drift_rate,\n",
    "            'tim_drift': tim_drift,\n",
    "            'trial': trial_data,\n",
    "            'threshold_go': threshold_go,\n",
    "            'nd_time' :  nd_time\n",
    "            }\n",
    "            \n",
    "        elif model == 2:\n",
    "            trial_params= {\n",
    "            'sigma': sigma,\n",
    "            'trial': trial_data,\n",
    "            'drift_weight': drift_weight,\n",
    "            'threshold_drift': threshold_drift,\n",
    "            'drift_rate': None,\n",
    "            'tim_drift': time_drift,    \n",
    "            'threshold_go': threshold_go,\n",
    "            'nd_time': nd_time\n",
    "            }\n",
    "            \n",
    "        elif model == 3:\n",
    "            trial_params = {\n",
    "                'sigma': sigma,\n",
    "                'trial': trial_data,\n",
    "                'drift_weight': drift_weight,\n",
    "                'threshold_drift': None,\n",
    "                'drift_rate': None,\n",
    "                'tim_drift': time_drift,    \n",
    "                'threshold_go': threshold_go,\n",
    "                'nd_time': nd_time \n",
    "                }\n",
    "            \n",
    "        model_drift, time , rt, resp = timed_integrator(par_func, m_func, stoch_var, X0, T, dt, **trial_params)\n",
    "\n",
    "        # write out information in data frame\n",
    "        sim_drift.iloc[idx,0:len(model_drift)] = model_drift.T[0]\n",
    "        sim_time.iloc[idx,0:len(time)] = time.T[0]\n",
    "        sim_rt.iloc[idx] = rt\n",
    "        sim_resp.iloc[idx] = resp\n",
    "                                             \n",
    "    try:\n",
    "        \n",
    "        # compute chi squared\n",
    "        go_sim_rt = sim_rt[sim_resp=='go']\n",
    "        bins_est = np.histogram(go_sim_rt, bins=num_bins, range=(0, range_max), density=False)[0]\n",
    "        bins_est = np.hstack([bins_est, len(sim_resp[sim_resp == 'nogo'])])\n",
    "        \n",
    "        if np.any(bins_est == 0):\n",
    "            print('zero division detected, needed to correct')\n",
    "            bins_est[bins_est == 0] = 1\n",
    "        \n",
    "        output, p = scipy.stats.chisquare(bins_obs, bins_est)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # if something goes wrong, let us know a few things:\n",
    "        print(sim_rt)\n",
    "        print(x)\n",
    "        print('the drift rate was: {}'.format(drift_rate))\n",
    "        print('sigma was: {}'.format(sigma))\n",
    "        \n",
    "        raise e\n",
    "    if np.isnan(output) or (not np.isfinite(output)):\n",
    "        print('nan detected')\n",
    "    #print('objective evaluated at the following values {}'.format(trial_params))\n",
    "    #print('the discovered p_value was: {}'.format(p))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_sub_m1 = functools.partial(gen_objective, df = sub_dat, m_func = model1, par_func = get_params_model1, model = 1, rts = true_rt, resps = true_resp)\n",
    "obj_sub_m2 = functools.partial(gen_objective, df = sub_dat, m_func = model2, par_func = get_params_model2, model = 2, rts = true_rt, resps = true_resp)\n",
    "obj_sub_m3 = functools.partial(gen_objective, df = sub_dat, m_func = model3, par_func = get_params_model3, model = 3, rts = true_rt, resps = true_resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the parameter space where we want to look\n",
    "params_m1 = []\n",
    "\n",
    "for sub in np.unique(exp_des.subject):\n",
    "    \n",
    "    print('estimating subject {}'.format(sub))\n",
    "    sub_dat = exp_des[exp_des.subject == sub].reset_index(drop = True)\n",
    "    true_rt = sub_dat.rea_time\n",
    "    true_resp = sub_dat.goResp\n",
    "    \n",
    "    obj_sub_m1 = functools.partial(gen_objective, df = sub_dat, m_func = model1, par_func = get_params_model1, model = 1, rts = true_rt, resps = true_resp)\n",
    "\n",
    "    space_m1 = [(0.0, 2.0),#drift rate\n",
    "            (0.0, 2.0), # tim_drift\n",
    "            (0.0, 1.0)] # non decision time\n",
    "\n",
    "    # run the optimizer\n",
    "    try:\n",
    "        r1 = gp_minimize(obj_sub_m1,space_m1,n_calls=20,random_state=1);   \n",
    "    except ValueError as e:\n",
    "        print(r1)\n",
    "        raise e\n",
    "        \n",
    "    params_m1.append(r1.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r1.x)\n",
    "skopt.plots.plot_objective(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_m2 = []\n",
    "\n",
    "for sub in np.unique(exp_des.subject):\n",
    "    \n",
    "    print('estimating subject {}'.format(sub))\n",
    "    sub_dat = exp_des[exp_des.subject == sub].reset_index(drop = True)\n",
    "    true_rt = sub_dat.rea_time\n",
    "    true_resp = sub_dat.goResp\n",
    "    \n",
    "    obj_sub_m2 = functools.partial(gen_objective, df = sub_dat, m_func = model2, par_func = get_params_model2, model = 2, rts = true_rt, resps = true_resp)\n",
    "\n",
    "    space_m2 = [(0.0,10.0),#drift weight\n",
    "              (0.0, 1.0), #threshold drift\n",
    "              (0.0, 2.0), # time drift\n",
    "              (0.0, 1.0)] # non decision time\n",
    "\n",
    "    # run the optimizer\n",
    "    try:\n",
    "        r2 = gp_minimize(obj_sub_m2,space_m2,n_calls=20,random_state=1);   \n",
    "    except ValueError as e:\n",
    "        print(r2)\n",
    "        raise e\n",
    "        \n",
    "    params_m2.append(r2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2.x)\n",
    "skopt.plots.plot_objective(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter space where we want to look\n",
    "params_m3 = []\n",
    "\n",
    "for sub in np.unique(exp_des.subject):\n",
    "    \n",
    "    print('estimating subject {}'.format(sub))\n",
    "    sub_dat = exp_des[exp_des.subject == sub].reset_index(drop = True)\n",
    "    true_rt = sub_dat.rea_time\n",
    "    true_resp = sub_dat.goResp\n",
    "    \n",
    "    obj_sub_m3 = functools.partial(gen_objective, df = sub_dat, m_func = model3, par_func = get_params_model3, model = 3, rts = true_rt, resps = true_resp)\n",
    "    \n",
    "    space_m3 = [(0.0,5.0),# drift weight\n",
    "             (0.0,2.0), # time drift\n",
    "             (0.0, 1.0)]# non-decision time\n",
    "\n",
    "    # run the optimizer\n",
    "    try:\n",
    "        r3 = gp_minimize(obj_sub_m3,space_m3,n_calls=20,random_state=1);   \n",
    "    except ValueError as e:\n",
    "        print(r3)\n",
    "        raise e\n",
    "    \n",
    "    params_m3.append(r3.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r3.x)\n",
    "skopt.plots.plot_objective(r3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm1 = pd.DataFrame(params_m1, columns = ['drift_rate', 'time_drift', 'nd_time'], index = np.unique(exp_des.subject))\n",
    "pm2 = pd.DataFrame(params_m2, columns = ['drift_weight', 'threshold_drift', 'time_drift', 'nd_time'], index = np.unique(exp_des.subject))\n",
    "pm3 = pd.DataFrame(params_m3, columns = ['drift_weight', 'time_drift', 'nd_time'], index = np.unique(exp_des.subject))\n",
    "\n",
    "pm1.to_csv('params_m1.csv')\n",
    "pm2.to_csv('params_m2.csv')\n",
    "pm3.to_csv('params_m3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare the models to the simulation visually\n",
    "\n",
    "#sub_fit, sf_axs = plt.subplots(1,3, figsize = [15,5])\n",
    "full_init = False\n",
    "\n",
    "for sub in np.unique(exp_des.subject):\n",
    "    \n",
    "    print('loading subject {}'.format(sub))\n",
    "    sub_dat = exp_des[exp_des.subject == sub].reset_index(drop = True)\n",
    "    \n",
    "    trial_n = len(sub_dat)\n",
    "\n",
    "    est_m1_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "    est_m2_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "    est_m3_drift = pd.DataFrame(np.zeros((trial_n,len(T))))\n",
    "\n",
    "    est_m1_rt = pd.Series(np.zeros(trial_n))\n",
    "    est_m2_rt = pd.Series(np.zeros(trial_n))\n",
    "    est_m3_rt = pd.Series(np.zeros(trial_n))\n",
    "\n",
    "    est_m1_resp = pd.Series(np.zeros(trial_n))\n",
    "    est_m2_resp = pd.Series(np.zeros(trial_n))\n",
    "    est_m3_resp = pd.Series(np.zeros(trial_n))\n",
    "\n",
    "    for idx, trial in enumerate(np.unique(sub_dat.index)):\n",
    "\n",
    "        # get data from current trial only\n",
    "        trial_data = long_format(sub_dat, trial) \n",
    "        trial_data.reset_index(drop=True, inplace = True)\n",
    "        #print(trial_data.loc[0])\n",
    "        # set parameters for drift\n",
    "\n",
    "        trial_params1 = {\n",
    "            'sigma': 1,\n",
    "            'trial': trial_data,\n",
    "            'drift_weight': None,\n",
    "            'threshold_drift': None,\n",
    "            'drift_rate': pm1.loc[sub,'drift_rate'],\n",
    "            'tim_drift': pm1.loc[sub,'time_drift'],    \n",
    "            'threshold_go': 1,\n",
    "            'nd_time': pm1.loc[sub, 'nd_time'] \n",
    "            }\n",
    "\n",
    "        trial_params2= {\n",
    "            'sigma': 1,\n",
    "            'trial': trial_data,\n",
    "            'drift_weight': pm2.loc[sub, 'drift_weight'],\n",
    "            'threshold_drift': pm2.loc[sub, 'threshold_drift'],\n",
    "            'drift_rate': None,\n",
    "            'tim_drift': pm2.loc[sub,'time_drift'],    \n",
    "            'threshold_go': 1,\n",
    "            'nd_time': pm2.loc[sub, 'nd_time']\n",
    "            }\n",
    "\n",
    "        trial_params3= {\n",
    "            'sigma': 1,\n",
    "            'trial': trial_data,\n",
    "            'drift_weight': pm3.loc[sub,'drift_weight'],\n",
    "            'threshold_drift': None,\n",
    "            'drift_rate': None,\n",
    "            'tim_drift': pm3.loc[sub,'time_drift'],    \n",
    "            'threshold_go': 1,\n",
    "            'nd_time': pm3.loc[sub,'nd_time'] \n",
    "            }\n",
    "\n",
    "        # run drift diffusion    \n",
    "        est_m1, est_time_m1, est_rt_m1,est_res_m1 = timed_integrator(get_params_model1, model1, stoch_var, X0, T, dt, **trial_params1)\n",
    "        est_m2, est_time_m2, est_rt_m2,est_res_m2 = timed_integrator(get_params_model2, model2, stoch_var, X0, T, dt, **trial_params2)\n",
    "        est_m3, est_time_m3, est_rt_m3,est_res_m3 = timed_integrator(get_params_model3, model3, stoch_var, X0, T, dt, **trial_params3)\n",
    "\n",
    "        # write drift result to table\n",
    "        est_m1_drift.iloc[idx,:] = est_m1.T[0]\n",
    "        est_m1_rt.iloc[idx] = est_rt_m1\n",
    "        est_m1_resp.iloc[idx] = est_res_m1\n",
    "\n",
    "        est_m2_drift.iloc[idx,:] = est_m2.T[0]\n",
    "        est_m2_rt.iloc[idx] = est_rt_m2\n",
    "        est_m2_resp.iloc[idx] = est_res_m2\n",
    "\n",
    "        est_m3_drift.iloc[idx,:] = est_m3.T[0]\n",
    "        est_m3_rt.iloc[idx] = est_rt_m3\n",
    "        est_m3_resp.iloc[idx] = est_res_m3\n",
    "\n",
    "    \n",
    "    simulated_answer = pd.concat([est_m1_rt, est_m1_resp, est_m2_rt, est_m2_resp, est_m3_rt, est_m3_resp], axis = 1)\n",
    "    simulated_answer.columns = ['m1_rt', 'm1_resp', 'm2_rt', 'm2_resp','m3_rt', 'm3_resp']\n",
    "    simulated_answer = pd.concat([sub_dat, simulated_answer], axis =1)\n",
    "    est_m1_drift['subject'] = sub\n",
    "    est_m2_drift['subject'] = sub\n",
    "    est_m3_drift['subject'] = sub\n",
    "    \n",
    "    if not full_init:\n",
    "        \n",
    "        full_sim = simulated_answer\n",
    "        full_m1_drift = est_m1_drift\n",
    "        full_m2_drift = est_m2_drift\n",
    "        full_m3_drift = est_m3_drift\n",
    "        \n",
    "        full_init = True\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        full_sim = pd.concat([full_sim, simulated_answer], axis = 0)\n",
    "        full_m1_drift = pd.concat([full_m1_drift, est_m1_drift], axis = 0)\n",
    "        full_m2_drift = pd.concat([full_m2_drift, est_m2_drift], axis = 0) \n",
    "        full_m3_drift = pd.concat([full_m3_drift, est_m3_drift], axis = 0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sim.to_csv('all_resp_simulated.csv')\n",
    "full_m1_drift.to_csv('all_m1_drift_simulated.csv')\n",
    "full_m2_drift.to_csv('all_m2_drift_simulated.csv')\n",
    "full_m3_drift.to_csv('all_m3_drift_simulated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sim.reset_index(drop=True, inplace = True)\n",
    "full_m1_drift.reset_index(drop=True, inplace = True)\n",
    "full_m2_drift.reset_index(drop=True, inplace = True)\n",
    "full_m3_drift.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.1 \n",
    "bins_sim = math.ceil((1 - 0.0)/t)\n",
    "bins_est = math.ceil((1 - 0.0)/t)\n",
    "\n",
    "sf_axs[0].hist(est_m1_rt[est_m1_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est,range= [0,1])\n",
    "sf_axs[0].hist(true_rt[true_resp == 1], alpha = 0.5, label = 'simulated', bins = bins_sim,range= [0,1])\n",
    "sf_axs[0].legend()\n",
    "sf_axs[1].hist(est_m2_rt[est_m2_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est,range= [0,1])\n",
    "sf_axs[1].hist(true_rt[true_resp == 1], alpha = 0.5, label = 'simulated', bins = bins_sim,range= [0,1])\n",
    "sf_axs[1].legend()\n",
    "sf_axs[2].hist(est_m3_rt[est_m3_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est, range= [0,1])\n",
    "sf_axs[2].hist(true_rt[true_resp == 1], alpha = 0.5, label = 'simulated', bins = bins_sim, range= [0,1])\n",
    "\n",
    "sub_fit, sf_axs = plt.subplots(1,3, figsize = [15,5])\n",
    "sf_axs[2].legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_fit, sf_axs = plt.subplots(1,3, figsize = [15,5])\n",
    "t = 0.1 \n",
    "bins_sim = math.ceil((1 - 0.0)/t)\n",
    "bins_est = math.ceil((1 - 0.0)/t)\n",
    "\n",
    "sf_axs[0].hist(est_m1_rt[est_m1_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est,range= [0,1])\n",
    "sf_axs[0].hist(true_rt[true_resp == 1], alpha = 0.5, label = 'simulated', bins = bins_sim,range= [0,1])\n",
    "sf_axs[0].legend()\n",
    "sf_axs[1].hist(est_m2_rt[est_m2_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est,range= [0,1])\n",
    "sf_axs[1].hist(true_rt[true_resp == 1], alpha = 0.5, label = 'simulated', bins = bins_sim,range= [0,1])\n",
    "sf_axs[1].legend()\n",
    "sf_axs[2].hist(est_m3_rt[est_m3_resp == 'go'], alpha = 0.5, label = 'estimate', bins = bins_est, range= [0,1])\n",
    "sf_axs[2].hist(true_rt[true_resp == 1], alpha = 0.5, label = 'simulated', bins = bins_sim, range= [0,1])\n",
    "sf_axs[2].legend()\n",
    "\n",
    "sub_fit;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
